# game-deal-tracker/crawlers/steam_crawler.py

import requests
import re
import time
from datetime import datetime
from bs4 import BeautifulSoup
from sqlalchemy.orm import Session
from sqlalchemy import func
from db.models import Deal, SteamMetadata 
from config.database import SessionLocal

# ìŠ¤íŒ€ ê²€ìƒ‰ API ì—”ë“œí¬ì¸íŠ¸
# specials=1 (í• ì¸ ìƒí’ˆ), cc=kr (í•œêµ­ ê¸°ì¤€), l=koreana (ì–¸ì–´ ì„¤ì •)
STEAM_SEARCH_URL = "https://store.steampowered.com/search/results/?query&start={start}&count=100&dynamic_data=&sort_by=_ASC&snr=1_7_7_151_7&infinite=1&specials=1&cc=kr&l=koreana"

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7'
}

def fetch_steam_sales(limit=500):
    """ìŠ¤íŒ€ í• ì¸ ê²Œì„ ëª©ë¡ì„ ê°€ì ¸ì™€ íŒŒì‹±í•©ë‹ˆë‹¤."""
    all_deals = []
    start = 0
    
    print(f"ğŸš‚ Fetching Steam sales (Target: ~{limit} items)...")

    while len(all_deals) < limit:
        try:
            url = STEAM_SEARCH_URL.format(start=start)
            response = requests.get(url, headers=HEADERS)
            
            if response.status_code != 200:
                print(f"  - Failed to fetch Steam data: {response.status_code}. Stopping.")
                break
                
            data = response.json()
            html_content = data.get('results_html')
            
            if not html_content:
                print("  - No more results found. Stopping.")
                break
                
            soup = BeautifulSoup(html_content, 'html.parser')
            rows = soup.select('a.search_result_row')
            
            if not rows:
                break
                
            for row in rows:
                deal_info = parse_steam_row(row)
                if deal_info:
                    all_deals.append(deal_info)
            
            # ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™
            start += len(rows)
            print(f"  - Fetched {len(all_deals)} deals so far...")
            
            # ë„ˆë¬´ ë¹ ë¥¸ ìš”ì²­ ë°©ì§€
            time.sleep(1)
            
        except Exception as e:
            print(f"âŒ Error during Steam crawling: {e}")
            break
            
    return all_deals[:limit]

def parse_steam_row(row):
    """HTML í–‰ í•˜ë‚˜ì—ì„œ ê²Œì„ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        title = row.select_one('span.title').text.strip()
        url = row['href']
        
        # App ID ì¶”ì¶œ (deal_idë¡œ ì‚¬ìš©ë  ìŠ¤íŒ€ ê³ ìœ  ID)
        app_id_str = row.get('data-ds-appid')
        steam_app_id = int(app_id_str.split(',')[0]) if app_id_str else None
        if not steam_app_id: return None
        
        # ì´ë¯¸ì§€ URL (ê³ í•´ìƒë„ í—¤ë” ì´ë¯¸ì§€ë¡œ ë³€í™˜ ì‹œë„)
        img_tag = row.select_one('div.search_capsule img')
        image_url = img_tag['src'].replace("capsule_sm_120", "header") if img_tag and img_tag.get('src') else None

        # ê°€ê²© ë° í• ì¸ìœ¨ ì¶”ì¶œ
        price_div = row.select_one('div.search_price')
        discount_span = row.select_one('div.search_discount span')
        
        if not discount_span or not price_div:
            return None 

        discount_rate = int(discount_span.text.replace('-', '').replace('%', ''))
        
        # ê°€ê²© íŒŒì‹± (ì •ê°€ + í• ì¸ê°€)
        price_text = price_div.select('strike')
        if not price_text:
            return None
            
        regular_price_text = price_text[0].get_text(strip=True)
        sale_price_tag = price_div.select_one('.search_price span:not([class])') # í• ì¸ê°€ í…ìŠ¤íŠ¸
        
        regular_price = float(re.sub(r'[^\d.]', '', regular_price_text.replace(',', '')))
        sale_price = float(re.sub(r'[^\d.]', '', sale_price_tag.get_text(strip=True).replace(',', ''))) if sale_price_tag else 0.0

        # ë¦¬ë·° ì •ë³´ ì¶”ì¶œ
        review_summary = ""
        positive_percent = 0
        total_reviews = 0
        
        review_span = row.select_one('span.search_review_summary')
        if review_span:
            tooltip = review_span.get('data-tooltip-html', '')
            review_parts = tooltip.split('<br>')
            if len(review_parts) > 0:
                review_summary = review_parts[0]
                
            # í¼ì„¼íŠ¸ ë° ê°œìˆ˜ ì¶”ì¶œ
            match = re.search(r'(\d+)%[^0-9]+([\d,]+)', tooltip)
            if match:
                positive_percent = int(match.group(1))
                total_reviews = int(match.group(2).replace(',', ''))
        
        # End Date: ìŠ¤íŒ€ ê²€ìƒ‰ ê²°ê³¼ì—ëŠ” ì—†ìœ¼ë¯€ë¡œ None
        
        return {
            "platform": "Steam",
            "title": title,
            "url": url,
            "image_url": image_url,
            "regular_price": regular_price,
            "sale_price": sale_price,
            "discount_rate": discount_rate,
            "deal_type": "Sale", # ìŠ¤íŒ€ í• ì¸ì€ Saleë¡œ ë¶„ë¥˜
            "is_active": True,
            "end_date": None, 
            "steam_meta": {
                "steam_app_id": steam_app_id,
                "review_summary": review_summary,
                "positive_review_percent": positive_percent,
                "total_reviews": total_reviews
            }
        }
    except Exception as e:
        # print(f"Row parsing error for Steam: {e}")
        return None

def save_steam_deals(db: Session):
    deals = fetch_steam_sales()
    if not deals:
        print("  - No Steam deals found.")
        return 0
        
    count_saved = 0
    count_updated = 0
    
    for data in deals:
        steam_meta_data = data.pop("steam_meta")
        
        try:
            existing_deal = db.query(Deal).filter(Deal.url == data['url']).first()
            
            if existing_deal:
                # Deal ì •ë³´ ì—…ë°ì´íŠ¸
                existing_deal.sale_price = data['sale_price']
                existing_deal.discount_rate = data['discount_rate']
                existing_deal.is_active = True
                
                # SteamMetadata ì—…ë°ì´íŠ¸
                if existing_deal.steam_meta:
                    for key, value in steam_meta_data.items():
                        setattr(existing_deal.steam_meta, key, value)
                else:
                    new_meta = SteamMetadata(deal_id=existing_deal.id, **steam_meta_data)
                    db.add(new_meta)
                    
                count_updated += 1
            else:
                # ì‹ ê·œ Deal ìƒì„±
                new_deal = Deal(**data)
                db.add(new_deal)
                db.flush() 
                
                # SteamMetadata ì—°ê²°
                new_meta = SteamMetadata(deal_id=new_deal.id, **steam_meta_data)
                db.add(new_meta)
                count_saved += 1
                
            db.commit()
            
        except Exception as e:
            db.rollback()
            print(f"âŒ Error saving Steam deal {data['title']}: {e}")
            
    print(f"âœ… Steam Crawler Summary: Added {count_saved}, Updated {count_updated}.")
    return count_saved

def crawl_steam():
    session = SessionLocal()
    try:
        save_steam_deals(session)
    finally:
        session.close()

if __name__ == "__main__":
    crawl_steam()